## This file is part of the CITAN library.
##
## Copyright 2011 Marek Gagolewski <gagolews@ibspan.waw.pl>
##
##
## CITAN is free software: you can redistribute it and/or modify
## it under the terms of the GNU Lesser General Public License as published by
## the Free Software Foundation, either version 3 of the License, or
## (at your option) any later version.
##
## CITAN is distributed in the hope that it will be useful,
## but WITHOUT ANY WARRANTY; without even the implied warranty of
## MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.See the
## GNU Lesser General Public License for more details.
##
## You should have received a copy of the GNU Lesser General Public License
## along with CITAN. If not, see <http://www.gnu.org/licenses/>.

#' @include biblio.internal.R
NA


#' /internal/
.lbsImportDocuments_GetSurvey <- function(conn, surveyDescription, originalFilename, verbose)
{
	query <- sprintf("INSERT INTO Biblio_Surveys('Description', 'FileName', 'Timestamp')
		VALUES(%s, %s, %s)",
		sqlStringOrNULL(surveyDescription),
		sqlStringOrNULL(originalFilename),
		sqlStringOrNULL(format(Sys.time(), "%Y-%m-%d %H:%M:%S"))
	);
	dbExecQuery(conn, query, TRUE);

	return(as.numeric(dbGetQuery(conn, "SELECT last_insert_rowid()")[1,1]));
}




#' /internal/
.lbsImportDocuments_GetIdLanguage <- function(conn, data, verbose)
{
	IdLanguage <- as.factor(data$Language);
	lev <- levels(IdLanguage);
	lev <- sqlEscapeTrim(lev);
	
	lev[nchar(lev) == 0] <- NA;
	
	existing <- which(!is.na(lev));
	n <- length(existing);
	
	## ----- prepare queries ------------------------
	queries1 <- sprintf("INSERT OR IGNORE INTO Biblio_Languages
	   ('Name') VALUES (UPPER('%s'));", lev[existing]);
	   
	queries2 <- sprintf("SELECT IdLanguage FROM Biblio_Languages
	   WHERE Name=UPPER('%s');", lev[existing]);
	
	
	## ----- exec    queries ------------------------
	for (i in 1:n)
	{
		dbExecQuery(conn, queries1[i], TRUE);
		levels(IdLanguage)[existing[i]] <- dbGetQuery(conn, queries2[i])[1,1];
	}

	return(IdLanguage);
}



#' /internal/
.lbsImportDocuments_Add_Get_idSource <- function(conn, issn, i, warnISSN)
{
	if (!is.na(issn))
	{
		issn <- sqlStringOrNULL(issn);
		idSource <- dbGetQuery(conn, sprintf("SELECT idSource FROM Biblio_Sources
			WHERE UPPER(ISSN_Print)=UPPER(%s) OR UPPER(ISSN_E)=UPPER(%s)",
			issn,
			issn
		));

		if (nrow(idSource)==0)
		{
			if (warnISSN)
			{
				warning(sprintf("no source with ISSN='%s' found for record %g. Setting IdSource=NA.",
					issn, i));
			}
			return(NA);
		}	else {
			if (nrow(idSource)>1 && warnISSN)
				warning(sprintf("more than one source with ISSN='%s' found for record %g. Using first.", issn, i));
			return(idSource[1,1]);
		}
	} else {
		return(NA);
	}
}





#' /internal/
.lbsImportDocuments_Add <- function(conn, record, idSurvey, i,
	updateDocumentIfExists, warnExactDuplicates, warnISSN, verbose)
{
	idSource <- sqlNumericOrNULL(.lbsImportDocuments_Add_Get_idSource(conn, record$ISSN, i, warnISSN));


	res <- dbGetQuery(conn, sprintf("SELECT IdDocument, IdSource, Title, BibEntry, Citations, Type
		FROM Biblio_Documents WHERE UPPER(UniqueId)=UPPER('%s');", record$UniqueId));

	if (nrow(res) != 0)
	{
		documentExists <- TRUE;
		idDocument <- res$IdDocument[1];
		
		if (warnExactDuplicates)
		{
			warning(sprintf("source at row=%g already exists (IdSource=%g, Title='%s', Citations=%g, Type='%s'). %s.",
				i, res$IdSource[1], res$Title[1], res$Citations[1], res$Type[1],
				ifelse(updateDocumentIfExists, "Updating", "Ignoring")));
		}
	
		if (updateDocumentIfExists)
		{
		
			 # will add authors once again later (they may be different)
			dbExecQuery(conn, sprintf("DELETE FROM Biblio_AuthorsDocuments WHERE IdDocument=%g;", idDocument), TRUE);
			
			
			# Update document
			query <- sprintf("UPDATE Biblio_Documents
				SET
					IdSource=%s,
					IdLanguage=%s,
					UniqueId='%s',
					Title='%s',
					BibEntry='%s',
					Year=%s,
					Pages=%s,
					Citations=%s,
					Type=%s
				WHERE IdDocument=%s;",
				
				idSource,
				record$IdLanguage,
				record$UniqueId,
				record$Title,
				record$BibEntry,
				record$Year,
				record$Pages,
				record$Citations,
				record$DocumentType,
				sqlNumericOrNULL(idDocument)
			);
			dbExecQuery(conn, query, TRUE);
		}
	} else {
		documentExists <- FALSE;
		
		
		# Insert document
		query <- sprintf("INSERT OR FAIL INTO Biblio_Documents ('IdSource', 'IdLanguage',
			'UniqueId', 'Title', 'BibEntry', 'Year', 'Pages', 'Citations', 'Type')
			VALUES(%s, %s, '%s', '%s', '%s', %s, %s, %s, %s);",
			idSource,
			record$IdLanguage,
			record$UniqueId,
			record$Title,
			record$BibEntry,
			record$Year,
			record$Pages,
			record$Citations,
			record$DocumentType
		);
		dbExecQuery(conn, query, TRUE);
		
		
		idDocument <- dbGetQuery(conn, "SELECT last_insert_rowid()")[1,1];
	}
	
	
	
	query <- sprintf("INSERT INTO Biblio_DocumentsSurveys (IdDocument, IdSurvey) VALUES(%s, %s);",
		sqlNumericOrNULL(idDocument), sqlNumericOrNULL(idSurvey));
	dbExecQuery(conn, query, TRUE);


	if (documentExists && !updateDocumentIfExists) return(FALSE);


	# add authors
	authors <- strsplit(record$Authors, "[[:space:]]*,[[:space:]]*")[[1]];
	stopifnot(length(authors)>0);
	for (j in 1:length(authors))
	{
		stopifnot(nchar(authors[j])>0);
		
		
		# Get idAuthor (and add him/her eventually)
		idAuthor <- dbGetQuery(conn, sprintf("SELECT IdAuthor FROM Biblio_Authors WHERE UPPER(Name)=UPPER(%s)",
			sqlStringOrNULL(authors[j])
		));
		if (nrow(idAuthor) == 0)
		{
			dbExecQuery(conn, sprintf("INSERT INTO Biblio_Authors(Name) VALUES(%s);", sqlStringOrNULL(authors[j])), TRUE);
			idAuthor <- dbGetQuery(conn, "SELECT last_insert_rowid()")[1,1];
		} else {
			idAuthor <- idAuthor[1,1];
		}
		

		query <- sprintf("INSERT OR IGNORE INTO Biblio_AuthorsDocuments(IdAuthor, IdDocument)
			VALUES(%s, %s);",
			sqlNumericOrNULL(idAuthor),
			sqlNumericOrNULL(idDocument));
		dbExecQuery(conn, query, TRUE);
	}
	
	return(!documentExists)
}



#' Imports publications from a special 14-column data frame to a Local Bibliometric Storage.
#' Such an input may be created e.g. with \code{\link{Scopus_ReadCSV}}.
#'
#'
#' \code{data} must consist of the following 14 columns (in order). Otherwise
#' the process will not be executed.
#' \tabular{llll}{
#' 1  \tab \code{Authors}       \tab character\tab  Author(s) name(s), comma-separated, surnames first.\cr
#' 2  \tab \code{Title}         \tab character\tab  Document title.\cr
#' 3  \tab \code{Year}          \tab numeric  \tab  Year of publication.\cr
#' 4  \tab \code{SourceTitle}   \tab character\tab  Title of the source containing the document.\cr
#' 5  \tab \code{Volume}        \tab character\tab  Volume.\cr
#' 6  \tab \code{Issue}         \tab character\tab  Issue.\cr
#' 7  \tab \code{ArticleNumber} \tab character\tab  Article number (identifier).\cr
#' 8  \tab \code{PageStart}     \tab numeric  \tab  Start page; numeric.\cr
#' 9  \tab \code{PageEnd}       \tab numeric  \tab  End page; numeric.\cr
#' 10 \tab \code{Citations}     \tab numeric  \tab  Number of citations.\cr
#' 11 \tab \code{UniqueId}      \tab character\tab  Unique document identifier. \cr
#' 12 \tab \code{ISSN}          \tab character\tab  ISSN of the source.\cr
#' 13 \tab \code{Language}      \tab factor   \tab  Language of the document.\cr
#' 14 \tab \code{DocumentType}  \tab factor   \tab  Type of the document.\cr
#' }
#'
#' \code{DocumentType} is one of \dQuote{Article}, \dQuote{Article in Press},
#'        \dQuote{Book}, \dQuote{Conference Paper}, \dQuote{Editorial}, \dQuote{Erratum},
#'        \dQuote{Letter}, \dQuote{Note}, \dQuote{Report},
#'        \dQuote{Review}, \dQuote{Short Survey}, or \code{NA} (other categories are interpreted as \code{NA}).
#'
#' Note that if \code{data} contains many records (>1000),
#' the import process may take a few minutes.
#'
#' Sources (e.g. journals) are identified by ISSNs (table \code{Biblio_Sources}).
#' Note that generally there is no need to concern about missing ISSNs of
#' conference proceedings.
#'
#' Each time a function is called, a new record in the table \code{Biblio_Surveys}
#' is created. Such surveys may be grouped using the \code{Description}
#' field, see \code{\link{lbsCreate}}.
#'
#' @title Import publications to a Local Bibliometric Storage.
#' @param conn a connection object as produced by \code{\link{lbsConnect}}.
#' @param data 14 column \code{data.frame} with bibliometric entries; see above.
#' @param surveyDescription description of the survey. Allows for documents grouping.
#' @param originalFilename original file name, \code{attr(data, "filename")} is used by default.
#' @param excludeRows a numeric vector with row numbers of \code{data} to exclude or \code{NULL}.
#' @param updateDocumentIfExists logical; if \code{TRUE}, then documents with the same \code{UniqueId} will be updated.
#' @param warnISSN logical; if \code{TRUE} then warnings are generated if a given ISSN in not found in the table \code{Biblio_Sources}.
#' @param warnExactDuplicates logical; \code{TRUE} to warn if exact duplicates are found (turned off by default).
#' @param verbose logical; \code{TRUE} to inform about the progress of the process.
#' @return  \code{TRUE} on success.
#' @seealso \code{\link{Scopus_ReadCSV}}, \code{\link{lbsConnect}}, \code{\link{lbsCreate}}
#' @examples
#' \dontrun{
#' conn <- lbsConnect("Bibliometrics.db");
#' ## ...
#' data <- Scopus_ReadCSV("db_Polish_MATH/Poland_MATH_1987-1993.csv");
#' lbsImportDocuments(conn, data, "Poland_MATH");
#' ## ...
#' dbDisconnect(conn);}
#' @export
lbsImportDocuments <- function(conn, data, surveyDescription="Default survey",
   originalFilename=attr(data, "filename"),
   excludeRows=NULL,  updateDocumentIfExists=TRUE,
   warnISSN=FALSE, warnExactDuplicates=FALSE, verbose=TRUE)
{
	CITAN:::.lbsCheckConnection(conn); # will stop on invalid/dead connection



	## ------ check data ------------------------------------------------------

	if (class(data) != "data.frame")
		stop("'data' is not a data.frame.");

	if (ncol(data) != 14 || any(names(data) != c("Authors", "Title", "Year", "SourceTitle", "Volume",
			"Issue", "ArticleNumber", "PageStart", "PageEnd", "Citations", "UniqueId", "ISSN", "Language", "DocumentType")))
		stop("incorrect format of 'data'.");

	if (class(data$Authors)!="character")       stop("column 'Authors' in 'data' should be 'character'.");
	if (class(data$Title)!="character")         stop("column 'Title' in 'data' should be 'character'.");
	if (class(data$Year)!="numeric")            stop("column 'Year' in 'data' should be 'numeric'.");
	if (class(data$SourceTitle)!="character")   stop("column 'SourceTitle' in 'data' should be 'character'.");
	if (class(data$Volume)!="character")        stop("column 'Volume' in 'data' should be 'character'.");
	if (class(data$Issue)!="character")         stop("column 'Issue' in 'data' should be 'character'.");
	if (class(data$ArticleNumber)!="character") stop("column 'ArticleNumber' in 'data' should be 'character'.");
	if (class(data$PageStart)!="numeric")       stop("column 'PageStart' in 'data' should be 'numeric'.");
	if (class(data$PageEnd)!="numeric")         stop("column 'PageEnd' in 'data' should be 'numeric'.");
	if (class(data$Citations)!="numeric")       stop("column 'Citations' in 'data' should be 'numeric'.");
	if (class(data$UniqueId)!="character")      stop("column 'UniqueId' in 'data' should be 'character'.");
	if (class(data$ISSN)!="character")          stop("column 'ISSN' in 'data' should be 'character'.");
	if (class(data$Language)!="factor")         stop("column 'Language' in 'data' should be 'factor'.");
	if (class(data$DocumentType)!="factor")     stop("column 'DocumentType' in 'data' should be 'factor'.");


	if (!is.null(excludeRows) && !is.numeric(excludeRows))
		stop("'excludeRows' must be numeric or NULL.");

	if (is.null(originalFilename) || is.na(originalFilename) || length(originalFilename) != 1)
		originalFilename <- "Unknown filename";

	if (is.null(surveyDescription) || is.na(surveyDescription) || length(surveyDescription) != 1)
		surveyDescription <- "Default survey";

	## -------------------------------------------------------------------
	
	if (verbose) cat("Importing documents and their authors... ");


	if (!is.null(excludeRows))
		data <- data[-excludeRows,];
	


	idSurvey <- .lbsImportDocuments_GetSurvey(conn, surveyDescription, originalFilename, verbose);
	stopifnot(length(idSurvey) == 1 && is.finite(idSurvey));

	data$IdLanguage <- sqlNumericOrNULL(.lbsImportDocuments_GetIdLanguage(conn, data, verbose));
	
	data$ISSN <- sqlEscapeTrim(data$ISSN);
	badissn <- which(!is.na(data$ISSN) & nchar(data$ISSN) != 8);
	if (length(badissn) > 0)
	{
		if (warnISSN) warning(sprintf("incorrect ISSNs for records %s. Setting NA.", paste(badissn, collapse=", ")));
		data$ISSN[badissn]  <- NA;
	}
	
	data$BibEntry <- sqlEscape(paste(
		sqlTrim(data$SourceTitle), 
		sqlTrim(data$Year), 
		sqlTrim(data$Volume), 
		sqlTrim(data$Issue), 
		sqlTrim(data$ArticleNumber), 
		data$PageStart, 
		data$PageEnd,
		sep=","));
		
	data$UniqueId <- sqlEscapeTrim(data$UniqueId);
	data$Title <- sqlEscapeTrim(data$Title);
	data$Year <- sqlNumericOrNULL(data$Year);
	data$Pages <- sqlNumericOrNULL(data$PageEnd-data$PageStart+1);
	data$Citations <- ifelse(is.finite(data$Citations), data$Citations, 0);
	data$DocumentType <- sqlSwitchOrNULL(data$DocumentType,
				CITAN:::.lbs_DocumentTypesFull,
				CITAN:::.lbs_DocumentTypesShort
			);

	## -------------------------------------------------------------------
	

	k <- 0L;
	n <- as.integer(nrow(data));
	
	if (verbose)
		window <- CITAN:::.gtk2.progressBar(0, n,
			info=sprintf("Importing %g documents and their authors to %s/%s...",
			n, surveyDescription, originalFilename));
	
	dbBeginTransaction(conn);
	for (i in 1:n)
	{
		if (.lbsImportDocuments_Add(conn, data[i,], idSurvey, i,
			updateDocumentIfExists, warnExactDuplicates, warnISSN, verbose))
		{
			k <- k+1L;
		}
		
		if (verbose) CITAN:::.gtk2.progressBar(i,n,window=window);
	}
	dbCommit(conn);


	if (verbose) cat(sprintf("OK, %g of %g records added to %s/%s.\n", k, n, surveyDescription, originalFilename));

	## -------------------------------------------------------------------

	return(TRUE);
}
